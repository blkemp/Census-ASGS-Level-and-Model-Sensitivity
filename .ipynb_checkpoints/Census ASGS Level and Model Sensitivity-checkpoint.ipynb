{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Census WFH   \n",
    "The goal of this workbook is to compare the efficacy of machine learning models based on different levels of spacial consolidation, based on the [Australian Statistical Geography Standard](https://www.abs.gov.au/websitedbs/D3310114.nsf/home/Australian+Statistical+Geography+Standard+(ASGS)) framework. the key questions are:   \n",
    "\n",
    "- Can we find a model for predicting with an R2 value > 0.7? (Based on [prior work](https://github.com/blkemp/ABS-Region-Data/tree/BKSubmission), I suspect the answer is yes).\n",
    "- Using this model, what is the impact on accuracy for feeding in data that is consolidated at a different level (e.g. neighborhood vs city vs county)?\n",
    "- How do models trained at differing levels of granularity compare in both baseline accuracy and generalisability? I.e. Are models trained with the most fine grained data more accurate, or are they prone to overfitting?\n",
    "\n",
    "As a starting point I will be utilising the [Australian Bureau of Statistics 2016 Census Datapacks](https://datapacks.censusdata.abs.gov.au/datapacks/) and attempting to predict \"working from home\" behaviours by region. Why this particular response vector? a) It just seems interesting and b) I suspect that demographic information available within the census itself (gender, age, profession and industry) will all be strongly related to both individuals' propensity to undertake working from home and their ability to do so with support from employers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "# Declare Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "import os\n",
    "from textwrap import wrap\n",
    "import operator\n",
    "\n",
    "# Set a variable for current notebook's path for various loading/saving mechanisms\n",
    "nb_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_plot_h(model, X_train, n_features):\n",
    "    '''\n",
    "    Takes a trained model and outputs a horizontal bar chart showing the \"importance\" of the\n",
    "    most impactful n features.\n",
    "    \n",
    "    INPUTS\n",
    "    model = Trained model in sklearn with  variable \".feature_importances_\". Trained supervised learning model.\n",
    "    X_train = Pandas Dataframe object. Feature set the training was completed using.\n",
    "    n_features = Int. Top n features you would like to plot.\n",
    "    '''\n",
    "    importances = model.feature_importances_\n",
    "    # Identify the n most important features\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    columns = X_train.columns.values[indices[:n_features]]\n",
    "    values = importances[indices][:n_features]\n",
    "    \n",
    "    columns = [ '\\n'.join(wrap(c, 20)) for c in columns ]\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize = (9,n_features))\n",
    "    plt.title(\"Normalized Weights for {} Most Predictive Features\".format(n_features), fontsize = 16)\n",
    "    plt.barh(np.arange(n_features), values, height = 0.6, align=\"center\", color = '#00A000', \n",
    "          label = \"Feature Weight\")\n",
    "    plt.barh(np.arange(n_features) - 0.3, np.cumsum(values), height = 0.2, align = \"center\", color = '#00A0A0', \n",
    "          label = \"Cumulative Feature Weight\")\n",
    "    plt.yticks(np.arange(n_features), columns)\n",
    "    plt.xlabel(\"Weight\", fontsize = 12)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_impact_plot(model, X_train, n_features, y_label):\n",
    "    '''\n",
    "    Takes a trained model and training dataset and synthesises the impacts of the top n features\n",
    "    to show their relationship to the response vector (i.e. how a change in the feature changes\n",
    "    the prediction). Returns n plots showing the variance for min, max, median, 1Q and 3Q.\n",
    "    \n",
    "    INPUTS\n",
    "    model = Trained model in sklearn with  variable \".feature_importances_\". Trained supervised learning model.\n",
    "    X_train = Pandas Dataframe object. Feature set the training was completed using.\n",
    "    n_features = Int. Top n features you would like to plot.\n",
    "    y_label = String. Description of response variable for axis labelling.\n",
    "    '''\n",
    "    # Display the n most important features\n",
    "    indices = np.argsort(model.feature_importances_)[::-1]\n",
    "    columns = X_train.columns.values[indices[:n_features]]\n",
    "    \n",
    "    sim_var = [[]]\n",
    "    \n",
    "    for col in columns:\n",
    "        base_pred = model.predict(X_train)\n",
    "        #add percentiles of base predictions to a df for use in reporting\n",
    "        base_percentiles = [np.percentile(base_pred, pc) for pc in range(0,101,25)]\n",
    "\n",
    "        # Create new predictions based on tweaking the parameter\n",
    "        # copy X, resetting values to align to the base information through different iterations\n",
    "        df_copy = X_train.copy()\n",
    "\n",
    "        for val in np.arange(-X_train[col].std(), X_train[col].std(), X_train[col].std()/50):\n",
    "            df_copy[col] = X_train[col] + val\n",
    "            # Add new predictions based on changed database\n",
    "            predictions = model.predict(df_copy)\n",
    "            \n",
    "            # Add percentiles of these predictions to a df for use in reporting\n",
    "            percentiles = [np.percentile(predictions, pc) for pc in range(0,101,25)]\n",
    "            \n",
    "            # Add variances between percentiles of these predictions and the base prediction to a df for use in reporting\n",
    "            percentiles = list(map(operator.sub, percentiles, base_percentiles))\n",
    "            percentiles = list(map(operator.truediv, percentiles, base_percentiles))\n",
    "            sim_var.append([val, col] + percentiles)\n",
    "\n",
    "    # Create a dataframe based off the arrays created above\n",
    "    df_predictions = pd.DataFrame(sim_var,columns = ['Value','Feature']+[0,25,50,75,100])\n",
    "    \n",
    "    # Create a subplot object based on the number of features\n",
    "    num_cols = 2\n",
    "    subplot_rows = int(n_features/num_cols) + int(n_features%num_cols)\n",
    "    fig, axs = plt.subplots(nrows = subplot_rows, ncols = num_cols, sharey = True, figsize=(15,5*subplot_rows))\n",
    "\n",
    "    nlines = 1\n",
    "\n",
    "    # Plot the feature variance impacts\n",
    "    for i in range(axs.shape[0]*axs.shape[1]):\n",
    "        if i < len(columns):\n",
    "            # Cycle through each plot object in the axs array and plot the appropriate lines\n",
    "            ax_row = int(i/num_cols)\n",
    "            ax_column = int(i%num_cols)\n",
    "            \n",
    "            axs[ax_row, ax_column].plot(df_predictions[df_predictions['Feature'] == columns[i]]['Value'],\n",
    "                     df_predictions[df_predictions['Feature'] == columns[i]][50])\n",
    "            \n",
    "            axs[ax_row, ax_column].set_title(\"\\n\".join(wrap(columns[i], int(100/num_cols))))\n",
    "            \n",
    "            # Create spacing between charts if chart titles happen to be really long.\n",
    "            nlines = max(nlines, axs[ax_row, ax_column].get_title().count('\\n'))\n",
    "\n",
    "            axs[ax_row, ax_column].set_xlabel('Simulated +/- change to feature'.format(y_label))\n",
    "            \n",
    "            # Format the y-axis as %\n",
    "            if ax_column == 0:\n",
    "                vals = axs[ax_row, ax_column].get_yticks()\n",
    "                axs[ax_row, ax_column].set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "                axs[ax_row, ax_column].set_ylabel('% change to {}'.format(y_label))\n",
    "        \n",
    "        # If there is a \"spare\" plot, hide the axis so it simply shows ans an empty space\n",
    "        else:\n",
    "            axs[int(i/num_cols),int(i%num_cols)].axis('off')\n",
    "    \n",
    "    # Apply spacing between subplots in case of very big headers\n",
    "    fig.subplots_adjust(hspace=0.5*nlines)\n",
    "    \n",
    "    # Return the plot\n",
    "    plt.tight_layout()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_series_abs(S):\n",
    "    'Takes a pandas Series object and returns the series sorted by absolute value'\n",
    "    temp_df = pd.DataFrame(S)\n",
    "    temp_df['abs'] = temp_df.iloc[:,0].abs()\n",
    "    temp_df.sort_values('abs', ascending = False, inplace = True)\n",
    "    return temp_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin importing and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata sheets\n",
    "df_meta_tables = pd.read_excel('{}\\Data\\Metadata\\Metadata_2016_GCP_DataPack.xlsx'.format(nb_path),\n",
    "                               sheet_name = 'Table number, name, population',\n",
    "                               skiprows=9)\n",
    "df_meta_measures = pd.read_excel('{}\\Data\\Metadata\\Metadata_2016_GCP_DataPack.xlsx'.format(nb_path),\n",
    "                               sheet_name = 'Cell descriptors information',\n",
    "                               skiprows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table number</th>\n",
       "      <th>Table name</th>\n",
       "      <th>Table population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>G55</td>\n",
       "      <td>Total Family Income (Weekly) by Labour Force S...</td>\n",
       "      <td>Couple families with children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>G56</td>\n",
       "      <td>Total Family Income (Weekly) by Labour Force S...</td>\n",
       "      <td>One parent families</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>G57</td>\n",
       "      <td>Occupation by Age by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>G58</td>\n",
       "      <td>Occupation by Hours Worked by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Table number                                         Table name  \\\n",
       "54          G55  Total Family Income (Weekly) by Labour Force S...   \n",
       "55          G56  Total Family Income (Weekly) by Labour Force S...   \n",
       "56          G57                           Occupation by Age by Sex   \n",
       "57          G58                  Occupation by Hours Worked by Sex   \n",
       "58          G59                    Method of Travel to Work by Sex   \n",
       "\n",
       "                            Table population  \n",
       "54             Couple families with children  \n",
       "55                       One parent families  \n",
       "56  Employed persons aged 15 years and over   \n",
       "57  Employed persons aged 15 years and over   \n",
       "58  Employed persons aged 15 years and over   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_tables.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_measures['Table number'] = df_meta_measures['DataPack file'].str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_measures = pd.merge(df_meta_measures, df_meta_tables, on='Table number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15535, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_measures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come up with some heuristics on what fields to drop and what to keep\n",
    "# E.g. do you really want Age splits? If so, then you need to filter out any \"Total\" Lines for them\n",
    "# if not then you need to filter out any lines with a metadata Long cell descriptor including the word \"[A/a]ge\"\n",
    "# Similar for splits by sex, whether you choose to delete the categories of \"Persons\" or only keep this field\n",
    "\n",
    "# Come up with a function to show the levels of data available within a table, i.e. age, sex, occupation, etc.\n",
    "# Build off this to create a function to filter for these levels as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_all_except_first_char(str_item):\n",
    "    str_replace = '{}{}'.format(str_item[:1],str_item[1:].lower())\n",
    "    df_meta_measures['Long'] = df_meta_measures['Long'].str.replace(str_item, str_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_measures['Long'] = df_meta_measures['Long'].str.replace('YEARS', 'years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think I should go back through this and remove the \"Total\" lines\n",
    "# Also sort the list by len in order to ensure substrings of other strings requiring change are done last\n",
    "replace_capitalisation_list = ['Not_stated',\n",
    "                               'None',\n",
    "                               'No_children',\n",
    "                               'Aboriginal_and_or_Torres_Strait_Islander',\n",
    "                               'Both_Aboriginal_and_Torres_Strait_Islander',\n",
    "                               'Torres_Strait_Islander',\n",
    "                               'Non_Indigenous',\n",
    "                               'New_Zealand',\n",
    "                               'South_Africa',\n",
    "                               'Sri_Lanka',\n",
    "                               'Bosnia_and_Herzegovina',\n",
    "                               'China_excludes_SARs_and_Taiwan',\n",
    "                               'Hong_Kong_SAR_of_China',\n",
    "                               'Korea_Republic_of_South',\n",
    "                               'Northern_Ireland',\n",
    "                               'Papua_New_Guinea',\n",
    "                               'South_Eastern_Europe',\n",
    "                               'Total_Responses',\n",
    "                               'Census_Night',\n",
    "                               'Elsewhere_in_Australia',\n",
    "                               'Birthplace_Australia',\n",
    "                               'Birthplace_Elsewhere',\n",
    "                               'Other_Language',\n",
    "                               'Age_of_Persons',\n",
    "                               'Count_of_Persons',\n",
    "                               'Average_number_of_Persons_per_bedroom',\n",
    "                               'Visitor_from_Different_SA2',\n",
    "                               'Visitor_from_Same_Statistical_Area_Level_2_SA2',\n",
    "                               'Western_Australia',\n",
    "                               'Northern_Territory',\n",
    "                               'Australian_Capital_Territory',\n",
    "                               'New_South_Wales',\n",
    "                               'Other_Territories',\n",
    "                               'China_excl_SARs_and_Taiwan',\n",
    "                               'United_Kingdom_Channel_Islands_and_Isle_of_Man',\n",
    "                               'The_Former_Yugoslav_Republic_of_Macedonia',\n",
    "                               'United_States_of_America',\n",
    "                               'Year_of_arrival_Before',\n",
    "                               'Speaks_English',\n",
    "                               'speaks_English',\n",
    "                               'Proficiency_in_English',\n",
    "                               'Proficiency_in_english',\n",
    "                               '_Before_2000',\n",
    "                               'Total_Year_of_arrival_not_stated',\n",
    "                               'Australian_Indigenous_Languages',\n",
    "                               'Chinese_Languages_Cantonese',\n",
    "                               'Chinese_Languages_Mandarin',\n",
    "                               'Chinese_Languages_Other',\n",
    "                               'Chinese_languages_Other',\n",
    "                               'Chinese_Languages_Total',\n",
    "                               'Indo_Aryan_Languages_Bengali',\n",
    "                               'Indo_Aryan_Languages_Hindi',\n",
    "                               'Indo_Aryan_Languages_Punjabi',\n",
    "                               'Indo_Aryan_Languages_Sinhalese',\n",
    "                               'Indo_Aryan_Languages_Urdu',\n",
    "                               'Indo_Aryan_Languages_Other',\n",
    "                               'Indo_Aryan_Languages_Total',\n",
    "                               'Persian_excluding_Dari',\n",
    "                               'Southeast_Asian_Austronesian_Languages_Filipino',\n",
    "                               'Southeast_Asian_Austronesian_Languages_Indonesian',\n",
    "                               'Southeast_Asian_Austronesian_Languages_Tagalog',\n",
    "                               'Southeast_Asian_Austronesian_Languages_Other',\n",
    "                               'Southeast_Asian_Austronesian_Languages_Total',\n",
    "                               'Christianity_Anglican',\n",
    "                               'Christianity_Assyrian_Apostolic',\n",
    "                               'Christianity_Baptist',\n",
    "                               'Christianity_Brethren',\n",
    "                               'Christianity_Catholic',\n",
    "                               'Christianity_Churches_of_Christ',\n",
    "                               'Christianity_Eastern_Orthodox',\n",
    "                               'Christianity_Jehovahs_Witnesses',\n",
    "                               'Christianity_Latter_day_Saints',\n",
    "                               'Christianity_Lutheran',\n",
    "                               'Christianity_Oriental_Orthodox',\n",
    "                               'Christianity_Other_Protestant',\n",
    "                               'Christianity_Pentecostal',\n",
    "                               'Christianity_Presbyterian_and_Reformed',\n",
    "                               'Christianity_Salvation_Army',\n",
    "                               'Christianity_Seventh_day_Adventist',\n",
    "                               'Christianity_Uniting_Church',\n",
    "                               'Christianity_Christianity_nfd',\n",
    "                               'Christianity_Other_Christian',\n",
    "                               'Christianity_Total',\n",
    "                               'Other_Religions_Australian_Aboriginal_Traditional_Religions',\n",
    "                               'Other_Religions_Sikhism',\n",
    "                               'Other_Religions_Other',\n",
    "                               'Other_Religions_Total',\n",
    "                               'Secular_Beliefs_and_Other_Spiritual_Beliefs_and_No_Religious_Affiliation_No_Religion_So_Described',\n",
    "                               'Secular_Beliefs_and_Other_Spiritual_Beliefs_and_No_Religious_Affiliation_Secular_Beliefs',\n",
    "                               'Secular_Beliefs_and_Other_Spiritual_Beliefs_and_No_Religious_Affiliation_Other_Spiritual_Beliefs',\n",
    "                               'Secular_Beliefs_and_Other_Spiritual_Beliefs_and_No_Religious_Affiliation_Total',\n",
    "                               'Infants_Primary',\n",
    "                               'Other_Non_Government',\n",
    "                               'Technical_or_Further_Educational_institution',\n",
    "                               'Full_Part_time',\n",
    "                               'University_or_other_Tertiary_Institution',\n",
    "                               'Males_Negative_Nil_income', #maybe look at this whole section\n",
    "                               'Females_Negative_Nil_income', #maybe look at this whole section\n",
    "                               'Persons_Negative_Nil_income', #maybe look at this whole section\n",
    "                               'Males_Personal_income_not_stated',#maybe look at this whole section\n",
    "                               'Feales_Personal_income_not_stated',#maybe look at this whole section\n",
    "                               'Persons_Personal_income_not_stated',#maybe look at this whole section\n",
    "                               'Cared_for_Own',\n",
    "                               'Cared_for_Other',\n",
    "                               'Visitor_from_within_Australia',\n",
    "                               'born_in_Australia',\n",
    "                               'Real_Estate_Agent',\n",
    "                               'with_Children',\n",
    "                               'with__No_children',\n",
    "                               'Flat_or_Apartment',\n",
    "                               'Graduate_Diploma_and_Graduate_Certificate_Level_Graduate_Diploma_Level', \n",
    "                               'Advanced_Diploma_and_Diploma_Level_Advanced_Diploma_and_Associate_Degree_Level',\n",
    "                               'Advanced_Diploma_and_Diploma_Advanced_Diploma_and_Associate_Degree_Level',\n",
    "                               'Certificate_Level_Certificate_III_and_IV_Level',\n",
    "                               'Certificate_Level_Certificate_I_and_II_Level',\n",
    "                               'Certificate_Level_Certificate_Level_nfd',\n",
    "                               'Graduate_Diploma_and_Graduate_Certificate_Level',\n",
    "                               'Advanced_Diploma_and_Diploma_Level_Diploma_Level',\n",
    "                               'Occupation_Inadequately_described',\n",
    "                               'Postgraduate_Degree_Level',\n",
    "                               'Master_Degree_Level',\n",
    "                               'Doctoral_Degree_Level',\n",
    "                               'Certificate_I_and_II_Level',\n",
    "                               'Certificate_III_and_IV_Level',\n",
    "                               'Advanced_Diploma_and_Diploma_Level',\n",
    "                               'Graduate_Certificate_Level',\n",
    "                               'Bachelor_Degree_Level',\n",
    "                               'Certificate_Level',\n",
    "                               'Different_SA2',\n",
    "                               'Same_Statistical_Area_Level_2',\n",
    "                               'Lone_Parent',\n",
    "                               'Worked_Full_Time',\n",
    "                               'Worked_Part_Time',\n",
    "                               'Away_From_Work',\n",
    "                               'Age_Of_Dependent_Children',\n",
    "                               '4_Years',\n",
    "                               '9_Years',\n",
    "                               '2_Years',\n",
    "                               '7_Years',\n",
    "                               '0_Years',\n",
    "                               'Hours_Worked',\n",
    "                               'Labour_Force_Status_Not_Stated',\n",
    "                               'Not_In_The_Labour_Force',\n",
    "                               'Labour_Force',\n",
    "                               'Looking_For_Full_Time_Work',\n",
    "                               'Looking_For_Part_Time_Work',\n",
    "                               'Natural_and_Physical_Sciences',\n",
    "                               'Information_Technology',\n",
    "                               'Engineering_and_Related_Technologies',\n",
    "                               'Architecture_and_Building',\n",
    "                               'Agriculture_Environmental_and_Related_Studies',\n",
    "                               'Management_and_Commerce',\n",
    "                               'Society_and_Culture',\n",
    "                               'Creative_Arts',\n",
    "                               'Food_Hospitality_and_Personal_Services',\n",
    "                               'Mixed_Field_Programmes',\n",
    "                               'Male_Parent',\n",
    "                               'Looking_For',\n",
    "                               'Hours_Worked_Not_Stated',\n",
    "                               'Inadequately_described_Not_stated',\n",
    "                               'Number_of_hours_worked_None',\n",
    "                               'Number_of_hours_worked_Not_stated',\n",
    "                               'Dependent_children_In_Couple_Families',\n",
    "                               'Negative_Nil',\n",
    "                               'Never_Married'\n",
    "                              ]\n",
    "\n",
    "\n",
    "# maybe have a rule for splitting directly after Males_/Females_/Persons_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_capitalisation_list.sort(key = len, reverse=True)\n",
    "for correction in replace_capitalisation_list:\n",
    "    lower_all_except_first_char(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequential</th>\n",
       "      <th>Short</th>\n",
       "      <th>Long</th>\n",
       "      <th>DataPack file</th>\n",
       "      <th>Profile table</th>\n",
       "      <th>Column heading description in profile</th>\n",
       "      <th>Table number</th>\n",
       "      <th>Table name</th>\n",
       "      <th>Table population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15515</th>\n",
       "      <td>G15516</td>\n",
       "      <td>Three_met_Bs_2_ot_met_ex_tr_F</td>\n",
       "      <td>Three_methods_Bus_and_two_other_methods_exclud...</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15516</th>\n",
       "      <td>G15517</td>\n",
       "      <td>Three_met_Bs_2_ot_met_ex_tr_P</td>\n",
       "      <td>Three_methods_Bus_and_two_other_methods_exclud...</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517</th>\n",
       "      <td>G15518</td>\n",
       "      <td>Three_meth_Othr_three_meth_M</td>\n",
       "      <td>Three_methods_Other_three_methods_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>G15519</td>\n",
       "      <td>Three_meth_Othr_three_meth_F</td>\n",
       "      <td>Three_methods_Other_three_methods_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15519</th>\n",
       "      <td>G15520</td>\n",
       "      <td>Three_meth_Othr_three_meth_P</td>\n",
       "      <td>Three_methods_Other_three_methods_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15520</th>\n",
       "      <td>G15521</td>\n",
       "      <td>Three_meth_Tot_three_meth_M</td>\n",
       "      <td>Three_methods_Total_three_methods_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15521</th>\n",
       "      <td>G15522</td>\n",
       "      <td>Three_meth_Tot_three_meth_F</td>\n",
       "      <td>Three_methods_Total_three_methods_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522</th>\n",
       "      <td>G15523</td>\n",
       "      <td>Three_meth_Tot_three_meth_P</td>\n",
       "      <td>Three_methods_Total_three_methods_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15523</th>\n",
       "      <td>G15524</td>\n",
       "      <td>Worked_home_M</td>\n",
       "      <td>Worked_at_home_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15524</th>\n",
       "      <td>G15525</td>\n",
       "      <td>Worked_home_F</td>\n",
       "      <td>Worked_at_home_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15525</th>\n",
       "      <td>G15526</td>\n",
       "      <td>Worked_home_P</td>\n",
       "      <td>Worked_at_home_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15526</th>\n",
       "      <td>G15527</td>\n",
       "      <td>Did_not_go_to_work_M</td>\n",
       "      <td>Did_not_go_to_work_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15527</th>\n",
       "      <td>G15528</td>\n",
       "      <td>Did_not_go_to_work_F</td>\n",
       "      <td>Did_not_go_to_work_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15528</th>\n",
       "      <td>G15529</td>\n",
       "      <td>Did_not_go_to_work_P</td>\n",
       "      <td>Did_not_go_to_work_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15529</th>\n",
       "      <td>G15530</td>\n",
       "      <td>Method_travel_to_work_ns_M</td>\n",
       "      <td>Method_of_travel_to_work_not_stated_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15530</th>\n",
       "      <td>G15531</td>\n",
       "      <td>Method_travel_to_work_ns_F</td>\n",
       "      <td>Method_of_travel_to_work_not_stated_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15531</th>\n",
       "      <td>G15532</td>\n",
       "      <td>Method_travel_to_work_ns_P</td>\n",
       "      <td>Method_of_travel_to_work_not_stated_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15532</th>\n",
       "      <td>G15533</td>\n",
       "      <td>Tot_M</td>\n",
       "      <td>Total_Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Males</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15533</th>\n",
       "      <td>G15534</td>\n",
       "      <td>Tot_F</td>\n",
       "      <td>Total_Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Females</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534</th>\n",
       "      <td>G15535</td>\n",
       "      <td>Tot_P</td>\n",
       "      <td>Total_Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>G59</td>\n",
       "      <td>Persons</td>\n",
       "      <td>G59</td>\n",
       "      <td>Method of Travel to Work by Sex</td>\n",
       "      <td>Employed persons aged 15 years and over</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sequential                          Short  \\\n",
       "15515     G15516  Three_met_Bs_2_ot_met_ex_tr_F   \n",
       "15516     G15517  Three_met_Bs_2_ot_met_ex_tr_P   \n",
       "15517     G15518   Three_meth_Othr_three_meth_M   \n",
       "15518     G15519   Three_meth_Othr_three_meth_F   \n",
       "15519     G15520   Three_meth_Othr_three_meth_P   \n",
       "15520     G15521    Three_meth_Tot_three_meth_M   \n",
       "15521     G15522    Three_meth_Tot_three_meth_F   \n",
       "15522     G15523    Three_meth_Tot_three_meth_P   \n",
       "15523     G15524                  Worked_home_M   \n",
       "15524     G15525                  Worked_home_F   \n",
       "15525     G15526                  Worked_home_P   \n",
       "15526     G15527           Did_not_go_to_work_M   \n",
       "15527     G15528           Did_not_go_to_work_F   \n",
       "15528     G15529           Did_not_go_to_work_P   \n",
       "15529     G15530     Method_travel_to_work_ns_M   \n",
       "15530     G15531     Method_travel_to_work_ns_F   \n",
       "15531     G15532     Method_travel_to_work_ns_P   \n",
       "15532     G15533                          Tot_M   \n",
       "15533     G15534                          Tot_F   \n",
       "15534     G15535                          Tot_P   \n",
       "\n",
       "                                                    Long DataPack file  \\\n",
       "15515  Three_methods_Bus_and_two_other_methods_exclud...           G59   \n",
       "15516  Three_methods_Bus_and_two_other_methods_exclud...           G59   \n",
       "15517            Three_methods_Other_three_methods_Males           G59   \n",
       "15518          Three_methods_Other_three_methods_Females           G59   \n",
       "15519          Three_methods_Other_three_methods_Persons           G59   \n",
       "15520            Three_methods_Total_three_methods_Males           G59   \n",
       "15521          Three_methods_Total_three_methods_Females           G59   \n",
       "15522          Three_methods_Total_three_methods_Persons           G59   \n",
       "15523                               Worked_at_home_Males           G59   \n",
       "15524                             Worked_at_home_Females           G59   \n",
       "15525                             Worked_at_home_Persons           G59   \n",
       "15526                           Did_not_go_to_work_Males           G59   \n",
       "15527                         Did_not_go_to_work_Females           G59   \n",
       "15528                         Did_not_go_to_work_Persons           G59   \n",
       "15529          Method_of_travel_to_work_not_stated_Males           G59   \n",
       "15530        Method_of_travel_to_work_not_stated_Females           G59   \n",
       "15531        Method_of_travel_to_work_not_stated_Persons           G59   \n",
       "15532                                        Total_Males           G59   \n",
       "15533                                      Total_Females           G59   \n",
       "15534                                      Total_Persons           G59   \n",
       "\n",
       "      Profile table Column heading description in profile Table number  \\\n",
       "15515           G59                               Females          G59   \n",
       "15516           G59                               Persons          G59   \n",
       "15517           G59                                 Males          G59   \n",
       "15518           G59                               Females          G59   \n",
       "15519           G59                               Persons          G59   \n",
       "15520           G59                                 Males          G59   \n",
       "15521           G59                               Females          G59   \n",
       "15522           G59                               Persons          G59   \n",
       "15523           G59                                 Males          G59   \n",
       "15524           G59                               Females          G59   \n",
       "15525           G59                               Persons          G59   \n",
       "15526           G59                                 Males          G59   \n",
       "15527           G59                               Females          G59   \n",
       "15528           G59                               Persons          G59   \n",
       "15529           G59                                 Males          G59   \n",
       "15530           G59                               Females          G59   \n",
       "15531           G59                               Persons          G59   \n",
       "15532           G59                                 Males          G59   \n",
       "15533           G59                               Females          G59   \n",
       "15534           G59                               Persons          G59   \n",
       "\n",
       "                            Table name  \\\n",
       "15515  Method of Travel to Work by Sex   \n",
       "15516  Method of Travel to Work by Sex   \n",
       "15517  Method of Travel to Work by Sex   \n",
       "15518  Method of Travel to Work by Sex   \n",
       "15519  Method of Travel to Work by Sex   \n",
       "15520  Method of Travel to Work by Sex   \n",
       "15521  Method of Travel to Work by Sex   \n",
       "15522  Method of Travel to Work by Sex   \n",
       "15523  Method of Travel to Work by Sex   \n",
       "15524  Method of Travel to Work by Sex   \n",
       "15525  Method of Travel to Work by Sex   \n",
       "15526  Method of Travel to Work by Sex   \n",
       "15527  Method of Travel to Work by Sex   \n",
       "15528  Method of Travel to Work by Sex   \n",
       "15529  Method of Travel to Work by Sex   \n",
       "15530  Method of Travel to Work by Sex   \n",
       "15531  Method of Travel to Work by Sex   \n",
       "15532  Method of Travel to Work by Sex   \n",
       "15533  Method of Travel to Work by Sex   \n",
       "15534  Method of Travel to Work by Sex   \n",
       "\n",
       "                               Table population  \n",
       "15515  Employed persons aged 15 years and over   \n",
       "15516  Employed persons aged 15 years and over   \n",
       "15517  Employed persons aged 15 years and over   \n",
       "15518  Employed persons aged 15 years and over   \n",
       "15519  Employed persons aged 15 years and over   \n",
       "15520  Employed persons aged 15 years and over   \n",
       "15521  Employed persons aged 15 years and over   \n",
       "15522  Employed persons aged 15 years and over   \n",
       "15523  Employed persons aged 15 years and over   \n",
       "15524  Employed persons aged 15 years and over   \n",
       "15525  Employed persons aged 15 years and over   \n",
       "15526  Employed persons aged 15 years and over   \n",
       "15527  Employed persons aged 15 years and over   \n",
       "15528  Employed persons aged 15 years and over   \n",
       "15529  Employed persons aged 15 years and over   \n",
       "15530  Employed persons aged 15 years and over   \n",
       "15531  Employed persons aged 15 years and over   \n",
       "15532  Employed persons aged 15 years and over   \n",
       "15533  Employed persons aged 15 years and over   \n",
       "15534  Employed persons aged 15 years and over   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_measures.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace any words following the word \"and\" with a lowercase version\n",
    "replace_ands = set()\n",
    "for cats in df_meta_measures.Long.unique():\n",
    "    try:\n",
    "        word = re.search('(?<=_and_)\\w+', cats).group(0).split('_')[0]\n",
    "        replace_ands.add('_and_{}'.format(word))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for repl in replace_ands:\n",
    "    df_meta_measures['Long'] = df_meta_measures['Long'].str.replace(repl,repl.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace any words following the word \"Occupation\" with a lowercase version\n",
    "replace_occs = set()\n",
    "for cats in df_meta_measures.Long.unique():\n",
    "    try:\n",
    "        word = re.search('(?<=ccupation_)\\w+', cats).group(0).split('_')[0]\n",
    "        replace_occs.add('ccupation_{}'.format(word))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for repl in replace_occs:\n",
    "    df_meta_measures['Long'] = df_meta_measures['Long'].str.replace(repl,repl.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequential</th>\n",
       "      <th>Short</th>\n",
       "      <th>Long</th>\n",
       "      <th>DataPack file</th>\n",
       "      <th>Profile table</th>\n",
       "      <th>Column heading description in profile</th>\n",
       "      <th>Table number</th>\n",
       "      <th>Table name</th>\n",
       "      <th>Table population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>G2847</td>\n",
       "      <td>China_exc_SARs_Taiw_Bef_1946</td>\n",
       "      <td>China_excl_sars_and_taiwan_Year_of_arrival_bef...</td>\n",
       "      <td>G10A</td>\n",
       "      <td>G10a</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>G10</td>\n",
       "      <td>Country of Birth of Person by Year of Arrival ...</td>\n",
       "      <td>Persons born overseas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sequential                         Short  \\\n",
       "2846      G2847  China_exc_SARs_Taiw_Bef_1946   \n",
       "\n",
       "                                                   Long DataPack file  \\\n",
       "2846  China_excl_sars_and_taiwan_Year_of_arrival_bef...          G10A   \n",
       "\n",
       "     Profile table Column heading description in profile Table number  \\\n",
       "2846          G10a                           Before 1946          G10   \n",
       "\n",
       "                                             Table name       Table population  \n",
       "2846  Country of Birth of Person by Year of Arrival ...  Persons born overseas  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_measures[df_meta_measures['Short'] == 'China_exc_SARs_Taiw_Bef_1946']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measure_cats = []\n",
    "for category in df_meta_measures.Long.tolist():\n",
    "    measure_cats.append(re.findall('[A-Z][^A-Z]*', category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export list to csv for framework to build reference table\n",
    "import csv\n",
    "\n",
    "with open(\"out.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(measure_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SA2 level data \n",
    "    # (start modelling at this level as a nice mid-point [plus it's the level I worked with in the previous project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalise this importation method to allow easy imports based on folder name (for SA level) \n",
    "# and a list of datapack files you want to amalgamate into a single dataframe\n",
    "def load_census_csv(table_list, statistical_area_code):\n",
    "    for index, table in enumerate(table_list):\n",
    "        #\n",
    "        # Probably want to put in a function here to check if the table is in the \"DataPack File\" group\n",
    "        # or just a raw table name. If not in the list, replace with the datapack names and loop through these\n",
    "        # if not in any list, print an error and continue.\n",
    "        #\n",
    "        if index==0:\n",
    "            df = pd.read_csv('{}\\Data\\{}\\AUST\\\\2016Census_{}_AUS_{}.csv'.format(nb_path,\n",
    "                                                                                statistical_area_code,\n",
    "                                                                                table,\n",
    "                                                                                statistical_area_code\n",
    "                                                                               ),\n",
    "                                       engine='python')\n",
    "        else:\n",
    "            temp_df = pd.read_csv('{}\\Data\\{}\\AUST\\\\2016Census_{}_AUS_{}.csv'.format(nb_path,\n",
    "                                                                                statistical_area_code,\n",
    "                                                                                table,\n",
    "                                                                                statistical_area_code\n",
    "                                                                               ),\n",
    "                                       engine='python')\n",
    "            merge_col = df.columns[0]\n",
    "            df = pd.merge(df, temp_df, on=merge_col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_data = load_census_csv(['G59','G53A'],'SA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new \"Work From Home Participation Rate\" vector to ensure consistency across regions\n",
    "# Base this off population who worked from home divided by total working population in the region\n",
    "'Worked_home_P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate correlations to check out items which stand out as potential drivers\n",
    "response_vector = 'INSERTVECTORHERE'\n",
    "sort_series_abs(df.dropna(subset=[solar]).corr().loc[:,response_vector])[1:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'features' and 'response' vectors into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "parameters = {'n_estimators':[10,20,40,80],\n",
    "              #'max_depth':[4,8,16,32,64],\n",
    "              'min_samples_leaf':[1,2,4]\n",
    "             }\n",
    "\n",
    "# TODO: Make a scoring object using make_scorer()\n",
    "scorer = make_scorer(r2_score)\n",
    "\n",
    "# TODO: Perform grid search on the regressor using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(rf, param_grid=parameters, scoring=scorer, verbose = 2)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_rf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred, y_test)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_plot_h(best_rf.feature_importances_, X_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space for initial thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
